---
prev-chapter: "Reasoning & Inference-Time Scaling"
prev-url: "14-reasoning.html"
page-title: Tool Use & Function Calling
next-chapter: "Synthetic Data & Distillation"
next-url: "15-synthetic.html"
---

# Tool Use & Function Calling

Language models using tools is a natural way to expand their capabilities, especially for high-precision tasks where external tools contain the information or for agents that need to interact with complex web systems.
These can be thought of in a few strategies where tool use is the general category.
An AI model uses any external tools by outputting special tokens to trigger a certain endpoint. 
These can be anything from highly specific tools, such as functions that return the weather at a specific place, to code interpreters or search engines that act as fundamental building blocks of complex behaviors.

The exact origin of the term "tool use" is not clear, but the origins of the idea far predates the post ChatGPT world where RLHF proliferated.
Early examples circ 2015 attempted to build systems predating modern language models, such as Neural Programmerâ€‘Interpreters (NPI) [@reed2015neural], "a recurrent and compositional neural network that learns to represent and execute programs."
As language models became more popular, many subfields were using integrations with external capabilities to boost performance. 
To obtain information outside of just the weights many used retrieval augmented generation [@lewis2020retrieval] or web browsing [@nakano2021webgpt].
Soon after, others were exploring language models integrated with programs [@gao2023pal] or tools [@parisi2022talm].

As the field matured, these models gained more complex abilities in addition to the vast improvements to the underlying language modeling.
For example, ToolFormer could use "a calculator, a Q&A system, two different search engines, a translation system, and a calendar" [@schick2023toolformerlanguagemodelsteach].
Soon after, Gorilla was trained to use 1645 APIs (from PyTorch Hub, TensorFlow Hub v2, and HuggingFace) and its evaluation APIBench became a foundation of the popular Berkeley Function Calling Leaderboard [@patil2023gorilla].
Since these early models, the diversity of actions called has grown substantially.


## Fundamentals of function calling

## Model Context Protocol (MCP)

## Multi-step tool reasoning

ReAct [@yao2023react]
> In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with and gather additional information from external sources such as knowledge bases or environments.

Multi-turn [@wang2025ragenunderstandingselfevolutionllm]

## Implementation
